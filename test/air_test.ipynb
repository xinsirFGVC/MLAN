{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import skimage\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "local_train = '/home/lvlab/Pytorch/object_air_train.npy'\n",
    "local_test = '/home/lvlab/Pytorch/object_air_test.npy'\n",
    "train_vectors = np.load(\"part_air_train.npy\")\n",
    "test_vectors = np.load(\"part_air_test.npy\")\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird_Dataset_Process(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, train_vectors, num, local_file, transform=None, transform2=None, \n",
    "                 transform3=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train_vectors = train_vectors\n",
    "        self.part_num = num\n",
    "        self.object_vectors = np.load(local_file)\n",
    "        self.transform2 = transform2\n",
    "        self.transform3 = transform3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "        \n",
    "        sample = {}\n",
    "        sample['image'] = copy.deepcopy(image)\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform2(sample['image'])\n",
    "        \n",
    "        image = skimage.util.img_as_ubyte(transform.resize(image, (448, 448))) \n",
    "        label = int(img_dir_label[1])\n",
    "        \n",
    "        obj_vec = self.object_vectors[idx]\n",
    "\n",
    "        x1, x2, y1, y2 = np.min(obj_vec[:, 0]), np.max(obj_vec[:, 0]), \\\n",
    "                        np.min(obj_vec[:, 1]), np.max(obj_vec[:, 1])\n",
    "        edge = 48\n",
    "        m1, m2, n1, n2 = int(np.maximum(x1 * 16 + 8 - edge, 0)), int(np.minimum(x2 * 16 + 8 + edge, 448)), \\\n",
    "                        int(np.maximum(y1 * 16 + 8 - edge, 0)), int(np.minimum(y2 * 16 + 8 + edge, 448))\n",
    "        \n",
    "        obj = image[m1:m2, n1:n2]\n",
    "        sample['object'] = copy.deepcopy(obj)\n",
    "        \n",
    "        if self.transform3:\n",
    "            sample['object'] = self.transform3(sample['object'])\n",
    "        \n",
    "        vectors = self.train_vectors[idx]\n",
    "        new_vectors = []\n",
    "        for i in range(self.part_num):\n",
    "            vectors_part = vectors[i]\n",
    "            if isinstance(vectors_part, list):\n",
    "                vectors_part = np.array(vectors_part)\n",
    "            num_p = vectors_part.shape[0]\n",
    "#             print(num_p)\n",
    "            cls_p = 0\n",
    "            lists = []\n",
    "            lab_set = {i for i in range(num_p)}\n",
    "            while(cls_p < num_p):\n",
    "                cls_l = []\n",
    "                start = lab_set.pop()\n",
    "                cls_l.append(start)\n",
    "                cls_p += 1\n",
    "                cls_new_p = True\n",
    "                while(cls_new_p):\n",
    "                    rm_l = []\n",
    "                    cls_new_p = False\n",
    "                    for k in lab_set:\n",
    "                        new_p = False\n",
    "                        for t in range(len(cls_l)):\n",
    "#                             print(pow(vectors_part[k, 0:2] - vectors_part[cls_l[t], 0:2], 2))\n",
    "                            dis = np.sum(pow(vectors_part[k, 0:2] - vectors_part[cls_l[t], 0:2], 2)) \n",
    "                            if dis <= 2:\n",
    "                                new_p = True\n",
    "                                break\n",
    "                        if new_p:\n",
    "                            cls_new_p = True\n",
    "                            rm_l.append(k)\n",
    "                            cls_l.append(k)\n",
    "                            cls_p += 1\n",
    "\n",
    "                    for kk in range(len(rm_l)):\n",
    "                        lab_set.remove(rm_l[kk])\n",
    "                lists.append(cls_l)\n",
    "#             print(len(lists))\n",
    "            l_n = [len(lists[i]) for i in range(len(lists))]\n",
    "#             print(l_n)\n",
    "            new_vector_index = lists[int(l_n.index(max(l_n)))]\n",
    "            new_vector = np.zeros((max(l_n), 4))\n",
    "            for i in range(max(l_n)):\n",
    "                new_vector[i] = vectors_part[new_vector_index[i]]\n",
    "            new_vectors.append(new_vector)\n",
    "        new_vectors = np.array(new_vectors)\n",
    "        \n",
    "        weights = np.zeros(self.part_num)\n",
    "        points = np.zeros((self.part_num, 2))\n",
    "        for i in range(self.part_num):\n",
    "            vectors_part = new_vectors[i]\n",
    "            if isinstance(vectors_part, list):\n",
    "                vectors_part = np.array(vectors_part)\n",
    "            weights[i] = np.sum(vectors_part[:, 2])/vectors_part.shape[0]\n",
    "            points[i, 0] = np.sum(vectors_part[:, 0])/vectors_part.shape[0]\n",
    "            points[i, 1] = np.sum(vectors_part[:, 1])/vectors_part.shape[0]\n",
    "            \n",
    "        index = np.argsort(weights)\n",
    "\n",
    "        for i in range(self.part_num):\n",
    "            vectors_part = new_vectors[index[i]]\n",
    "            if isinstance(vectors_part, list):\n",
    "                vectors_part = np.array(vectors_part)\n",
    "\n",
    "            x, y = np.round(points[index[i], 0] * 16 + 8), np.round(points[index[i], 1] * 16 + 8)\n",
    "            \n",
    "            l_d = np.maximum((np.max(vectors_part[:, 0]) - np.min(vectors_part[:, 0])), \\\n",
    "                            (np.max(vectors_part[:, 1]) - np.min(vectors_part[:, 1])))\n",
    "\n",
    "            if l_d <= 4:\n",
    "                l = 48\n",
    "            elif 4 < l_d <= 6:\n",
    "                l = 64\n",
    "            elif 6 < l_d <= 8:\n",
    "                l = 80\n",
    "            elif 8 < l_d <= 10:\n",
    "                l = 96\n",
    "            elif 10 < l_d <= 12:\n",
    "                l = 112\n",
    "            elif 12 < l_d <= 14:\n",
    "                l = 128\n",
    "            else:\n",
    "                l = 144\n",
    "\n",
    "            m1, m2, n1, n2 = int(np.maximum(0, x - l)), int(np.minimum(448, x + l)), \\\n",
    "                            int(np.maximum(0, y - l)), int(np.minimum(448, y + l))\n",
    "\n",
    "            sample['image%d' % (self.part_num - i - 1)] = image[m1:m2, n1:n2]            \n",
    "        \n",
    "        sample['label'] = label\n",
    "\n",
    "        if self.transform:\n",
    "            for i in range(self.part_num):\n",
    "                sample['image%d' % i] = self.transform(sample['image%d' % i])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(224),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.480, 0.511, 0.534], [0.221, 0.215, 0.246])\n",
    "            ])\n",
    "\n",
    "data_transform3 = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(224),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.480, 0.511, 0.534], [0.221, 0.215, 0.246])\n",
    "            ])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([448, 448]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.480, 0.511, 0.534], [0.221, 0.215, 0.246])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([448, 448]),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.480, 0.511, 0.534], [0.221, 0.215, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "root_dir = '/home/lvlab/Pytorch/air_data/'\n",
    "train_file = '/home/lvlab/Pytorch/air_data/train_list.txt'\n",
    "test_file = '/home/lvlab/Pytorch/air_data/test_list.txt'\n",
    "\n",
    "img_data = {'train': Bird_Dataset_Process(train_file, root_dir, train_vectors, 4, local_train, \n",
    "                                          data_transform, data_transforms['train'], data_transform3),\n",
    "                  'test': Bird_Dataset_Process(test_file, root_dir, test_vectors, 4, local_test, \n",
    "                                            data_transform, data_transforms['test'], data_transform3)}\n",
    "loader_img = {x: torch.utils.data.DataLoader(img_data[x], batch_size=2,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(img_data[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_part, model_obj, model_img, criterion):\n",
    "    start_time = time.time() \n",
    "    aa, bb, cc = 1, 1, 1\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    print(\"********************************************************\")\n",
    "    print(\"aa = \", aa, \" bb = \", bb, \" cc = \", cc)\n",
    "    # Iterate over data.\n",
    "    for i_batch, sample_batched in enumerate(loader_img['test']):\n",
    "        img0 = sample_batched['image0']\n",
    "        img1 = sample_batched['image1']\n",
    "        img2 = sample_batched['image2']\n",
    "        img3 = sample_batched['image3']\n",
    "        obj = sample_batched['object']\n",
    "        original = sample_batched['image']\n",
    "        labels = sample_batched['label']\n",
    "\n",
    "        obj = obj.to(device)\n",
    "        original = original.to(device)\n",
    "        img0 = img0.to(device)\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        img3 = img3.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = cc * (model_part(img0) + model_part(img1) + model_part(img2) + model_part(img3)) +  \\\n",
    "                aa * model_img(original) + bb * model_obj(obj)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * img0.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    phase = 'test'\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    cost_time = (time.time() - start_time)/60.0\n",
    "    print('{} 1 epoch time: {:.2f}min'.format(\n",
    "        phase, cost_time))\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "aa =  1  bb =  1  cc =  1\n",
      "test Loss: 1.4159 Acc: 0.8878\n",
      "test 1 epoch time: 2.28min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model_part = torch.load('/home/lvlab/Pytorch/part_air')\n",
    "model_obj = torch.load('/home/lvlab/Pytorch/object_air')\n",
    "model_img = torch.load('/home/lvlab/Pytorch/image_air')\n",
    "\n",
    "model_part = model_part.to(device)\n",
    "model_obj = model_obj.to(device)\n",
    "model_img = model_img.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "test_model(model_part, model_obj, model_img, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"random_model_ave1_max+3random_81.9%%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
