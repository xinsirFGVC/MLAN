{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import skimage\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.load(\"part_bird_train.npy\")\n",
    "test_vectors = np.load(\"part_bird_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird_Dataset_Process(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, train_vectors, num, transform=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train_vectors = train_vectors\n",
    "        self.part_num = num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "            \n",
    "        image = skimage.util.img_as_ubyte(transform.resize(image, (448, 448))) \n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {}\n",
    "        \n",
    "        vectors = self.train_vectors[idx]\n",
    "        new_vectors = []\n",
    "        for i in range(self.part_num):\n",
    "            vectors_part = vectors[i]\n",
    "            if isinstance(vectors_part, list):\n",
    "                vectors_part = np.array(vectors_part)\n",
    "            num_p = vectors_part.shape[0]\n",
    "#             print(num_p)\n",
    "            cls_p = 0\n",
    "            lists = []\n",
    "            lab_set = {i for i in range(num_p)}\n",
    "            while(cls_p < num_p):\n",
    "                cls_l = []\n",
    "                start = lab_set.pop()\n",
    "                cls_l.append(start)\n",
    "                cls_p += 1\n",
    "                cls_new_p = True\n",
    "                while(cls_new_p):\n",
    "                    rm_l = []\n",
    "                    cls_new_p = False\n",
    "                    for k in lab_set:\n",
    "                        new_p = False\n",
    "                        for t in range(len(cls_l)):\n",
    "#                             print(pow(vectors_part[k, 0:2] - vectors_part[cls_l[t], 0:2], 2))\n",
    "                            dis = np.sum(pow(vectors_part[k, 0:2] - vectors_part[cls_l[t], 0:2], 2)) \n",
    "                            if dis <= 2:\n",
    "                                new_p = True\n",
    "                                break\n",
    "                        if new_p:\n",
    "                            cls_new_p = True\n",
    "                            rm_l.append(k)\n",
    "                            cls_l.append(k)\n",
    "                            cls_p += 1\n",
    "\n",
    "                    for kk in range(len(rm_l)):\n",
    "                        lab_set.remove(rm_l[kk])\n",
    "                lists.append(cls_l)\n",
    "#             print(len(lists))\n",
    "            l_n = [len(lists[i]) for i in range(len(lists))]\n",
    "#             print(l_n)\n",
    "            new_vector_index = lists[int(l_n.index(max(l_n)))]\n",
    "            new_vector = np.zeros((max(l_n), 4))\n",
    "            for i in range(max(l_n)):\n",
    "                new_vector[i] = vectors_part[new_vector_index[i]]\n",
    "            new_vectors.append(new_vector)\n",
    "        new_vectors = np.array(new_vectors)\n",
    "        \n",
    "        weights = np.zeros(self.part_num)\n",
    "        points = np.zeros((self.part_num, 2))\n",
    "        for i in range(self.part_num):\n",
    "            vectors_part = new_vectors[i]\n",
    "            if isinstance(vectors_part, list):\n",
    "                vectors_part = np.array(vectors_part)\n",
    "            weights[i] = np.sum(vectors_part[:, 2])/vectors_part.shape[0]\n",
    "            points[i, 0] = np.sum(vectors_part[:, 0])/vectors_part.shape[0]\n",
    "            points[i, 1] = np.sum(vectors_part[:, 1])/vectors_part.shape[0]\n",
    "            \n",
    "        index = np.argsort(weights)\n",
    "\n",
    "        for i in range(self.part_num):\n",
    "            vectors_part = new_vectors[index[i]]\n",
    "            if isinstance(vectors_part, list):\n",
    "                vectors_part = np.array(vectors_part)\n",
    "\n",
    "            x, y = np.round(points[index[i], 0] * 16 + 8), np.round(points[index[i], 1] * 16 + 8)\n",
    "            \n",
    "            l_d = np.maximum((np.max(vectors_part[:, 0]) - np.min(vectors_part[:, 0])), \\\n",
    "                            (np.max(vectors_part[:, 1]) - np.min(vectors_part[:, 1])))\n",
    "\n",
    "            if l_d <= 4:\n",
    "                l = 48\n",
    "            elif 4 < l_d <= 6:\n",
    "                l = 64\n",
    "            elif 6 < l_d <= 8:\n",
    "                l = 80\n",
    "            elif 8 < l_d <= 10:\n",
    "                l = 96\n",
    "            elif 10 < l_d <= 12:\n",
    "                l = 112\n",
    "            elif 12 < l_d <= 14:\n",
    "                l = 128\n",
    "            else:\n",
    "                l = 144\n",
    "\n",
    "            m1, m2, n1, n2 = int(np.maximum(0, x - l)), int(np.minimum(448, x + l)), \\\n",
    "                            int(np.maximum(0, y - l)), int(np.minimum(448, y + l))\n",
    "\n",
    "            sample['image%d' % (self.part_num - i - 1)] = image[m1:m2, n1:n2]            \n",
    "        \n",
    "        sample['label'] = label\n",
    "\n",
    "        if self.transform:\n",
    "            for i in range(self.part_num):\n",
    "                sample['image%d' % i] = self.transform(sample['image%d' % i])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image2': tensor([[[-0.8893, -0.8722, -0.7865,  ..., -0.3242, -0.3070, -0.3070],\n",
      "         [-0.8550, -0.8379, -0.7694,  ..., -0.3242, -0.3070, -0.3070],\n",
      "         [-0.7694, -0.7694, -0.7352,  ..., -0.3070, -0.2899, -0.2899],\n",
      "         ...,\n",
      "         [-0.1872, -0.1872, -0.1872,  ..., -2.0709, -2.0709, -2.0709],\n",
      "         [-0.2043, -0.2043, -0.2043,  ..., -2.0538, -2.0709, -2.0709],\n",
      "         [-0.2043, -0.2043, -0.2214,  ..., -2.0538, -2.0709, -2.0709]],\n",
      "\n",
      "        [[-1.3637, -1.3463, -1.2940,  ...,  0.2049,  0.2223,  0.2223],\n",
      "         [-1.3289, -1.3115, -1.2766,  ...,  0.2049,  0.2223,  0.2223],\n",
      "         [-1.2417, -1.2417, -1.2417,  ...,  0.2223,  0.2397,  0.2397],\n",
      "         ...,\n",
      "         [ 0.3095,  0.3095,  0.3269,  ..., -0.8757, -0.8932, -0.8932],\n",
      "         [ 0.3269,  0.3269,  0.3269,  ..., -0.8583, -0.8757, -0.8757],\n",
      "         [ 0.3269,  0.3269,  0.3269,  ..., -0.8583, -0.8757, -0.8757]],\n",
      "\n",
      "        [[-0.8374, -0.8225, -0.7927,  ...,  0.9817,  0.9817,  0.9817],\n",
      "         [-0.8076, -0.7927, -0.7778,  ...,  0.9817,  0.9817,  0.9817],\n",
      "         [-0.7032, -0.7181, -0.7330,  ...,  0.9966,  0.9966,  0.9966],\n",
      "         ...,\n",
      "         [ 1.0861,  1.0861,  1.0861,  ...,  0.2362,  0.2511,  0.2511],\n",
      "         [ 1.1010,  1.1010,  1.1010,  ...,  0.2511,  0.2511,  0.2511],\n",
      "         [ 1.1010,  1.1010,  1.1010,  ...,  0.2511,  0.2511,  0.2511]]]), 'image1': tensor([[[-2.0709, -2.0538, -2.0709,  ..., -0.5810, -0.5639, -0.5639],\n",
      "         [-2.0366, -2.0366, -2.0538,  ..., -0.5468, -0.5297, -0.5468],\n",
      "         [-2.0538, -2.0709, -2.0709,  ..., -0.5125, -0.5125, -0.5297],\n",
      "         ...,\n",
      "         [-0.7865, -0.6324, -0.4612,  ..., -0.3755, -0.3584, -0.3070],\n",
      "         [-0.6667, -0.3584, -0.2214,  ..., -0.3755, -0.3755, -0.3070],\n",
      "         [-0.3927, -0.4612, -0.2043,  ..., -0.3413, -0.3584, -0.3413]],\n",
      "\n",
      "        [[-0.5097, -0.4749, -0.4923,  ...,  0.1352,  0.1526,  0.1700],\n",
      "         [-0.5097, -0.5097, -0.5097,  ...,  0.1700,  0.1875,  0.2049],\n",
      "         [-0.5097, -0.4923, -0.4923,  ...,  0.1875,  0.2049,  0.2049],\n",
      "         ...,\n",
      "         [-1.2243, -1.0500, -0.8932,  ...,  0.1875,  0.2049,  0.2572],\n",
      "         [-1.1197, -0.8234, -0.6666,  ...,  0.1875,  0.1875,  0.2572],\n",
      "         [-0.8583, -0.9454, -0.6666,  ...,  0.2049,  0.2049,  0.2223]],\n",
      "\n",
      "        [[ 0.8624,  0.8774,  0.8624,  ...,  0.9817,  0.9966,  0.9817],\n",
      "         [ 0.8774,  0.8624,  0.8624,  ...,  0.9817,  0.9966,  0.9966],\n",
      "         [ 0.8624,  0.8475,  0.8624,  ...,  0.9966,  1.0116,  1.0116],\n",
      "         ...,\n",
      "         [-0.9567, -0.8523, -0.7330,  ...,  0.9966,  0.9668,  0.9966],\n",
      "         [-0.8672, -0.6436, -0.5392,  ...,  0.9817,  0.9519,  0.9817],\n",
      "         [-0.6436, -0.7330, -0.5392,  ...,  0.9966,  0.9817,  0.9668]]]), 'image0': tensor([[[-1.8996, -1.8654, -1.6942,  ..., -2.0366, -2.0366, -2.0709],\n",
      "         [-1.8825, -1.7455, -1.4544,  ..., -2.0366, -2.0538, -2.0880],\n",
      "         [-1.6599, -1.4202, -1.0777,  ..., -2.0538, -2.0709, -2.1051],\n",
      "         ...,\n",
      "         [ 0.8061,  0.7718,  0.7718,  ..., -0.9407, -0.8550, -0.8379],\n",
      "         [ 0.8232,  0.8061,  0.8061,  ..., -1.0263, -0.9064, -0.8550],\n",
      "         [ 0.8574,  0.8403,  0.8403,  ..., -1.0948, -0.9407, -0.8893]],\n",
      "\n",
      "        [[-1.9738, -1.9738, -1.8518,  ..., -0.5620, -0.5620, -0.5794],\n",
      "         [-1.9738, -1.8692, -1.6078,  ..., -0.5620, -0.5794, -0.5969],\n",
      "         [-1.7995, -1.5729, -1.2766,  ..., -0.5620, -0.5794, -0.5969],\n",
      "         ...,\n",
      "         [ 0.2920,  0.2572,  0.2223,  ..., -1.1546, -1.1546, -1.2069],\n",
      "         [ 0.2920,  0.2746,  0.2397,  ..., -1.2069, -1.1720, -1.2243],\n",
      "         [ 0.3269,  0.2920,  0.2746,  ..., -1.2417, -1.2069, -1.2417]],\n",
      "\n",
      "        [[-1.4189, -1.3891, -1.2549,  ...,  0.8326,  0.8326,  0.8177],\n",
      "         [-1.4040, -1.2847, -1.0312,  ...,  0.8326,  0.8177,  0.8028],\n",
      "         [-1.2400, -1.0312, -0.7479,  ...,  0.8326,  0.8177,  0.8028],\n",
      "         ...,\n",
      "         [ 0.1765,  0.1467,  0.1020,  ..., -0.6436, -0.6883, -0.7927],\n",
      "         [ 0.1765,  0.1467,  0.1169,  ..., -0.6585, -0.6883, -0.7778],\n",
      "         [ 0.2064,  0.1616,  0.1467,  ..., -0.6883, -0.7032, -0.7927]]]), 'label': 1, 'image3': tensor([[[-2.1223, -2.0366, -1.8483,  ..., -1.0263, -1.0263, -1.0434],\n",
      "         [-2.1223, -2.0366, -1.8483,  ..., -1.0092, -0.9749, -0.9749],\n",
      "         [-2.1051, -2.0538, -1.8483,  ..., -0.9749, -0.9235, -0.9064],\n",
      "         ...,\n",
      "         [-2.1223, -1.8996, -0.8379,  ..., -0.1700, -0.1872, -0.1872],\n",
      "         [-2.1223, -1.8996, -0.8379,  ..., -0.1529, -0.1700, -0.1872],\n",
      "         [-2.1223, -1.8996, -0.8379,  ..., -0.1700, -0.1872, -0.2214]],\n",
      "\n",
      "        [[-2.2178, -2.0609, -1.3812,  ..., -0.1611, -0.1263, -0.1437],\n",
      "         [-2.2178, -2.0783, -1.3812,  ..., -0.1437, -0.1088, -0.1088],\n",
      "         [-2.2003, -2.0783, -1.3812,  ..., -0.1088, -0.0914, -0.0740],\n",
      "         ...,\n",
      "         [-2.2178, -1.9738, -0.6666,  ...,  0.3269,  0.3269,  0.3443],\n",
      "         [-2.2178, -1.9738, -0.6666,  ...,  0.3269,  0.3443,  0.3617],\n",
      "         [-2.2178, -1.9738, -0.6666,  ...,  0.3269,  0.3269,  0.3269]],\n",
      "\n",
      "        [[-1.6277, -1.4040, -0.4646,  ...,  0.8624,  0.8624,  0.8475],\n",
      "         [-1.6277, -1.4189, -0.4497,  ...,  0.8475,  0.8624,  0.8624],\n",
      "         [-1.6128, -1.4338, -0.4646,  ...,  0.8624,  0.8774,  0.8923],\n",
      "         ...,\n",
      "         [-1.6277, -1.4040, -0.1366,  ...,  1.0265,  1.0265,  1.0265],\n",
      "         [-1.6277, -1.3891, -0.1366,  ...,  1.0265,  1.0414,  1.0414],\n",
      "         [-1.6277, -1.3891, -0.1366,  ...,  1.0414,  1.0265,  1.0116]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lvlab/.tensorflow_pytorch/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/lvlab/.tensorflow_pytorch/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/lvlab/.tensorflow_pytorch/lib/python3.5/site-packages/skimage/util/dtype.py:130: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(224),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.486,0.499,0.432], [0.229,0.225,0.263])\n",
    "            ])\n",
    "\n",
    "root_dir = '/home/lvlab/Pytorch/images'\n",
    "train_file = '/home/lvlab/Pytorch/train.txt'\n",
    "test_file = '/home/lvlab/Pytorch/test.txt'\n",
    "\n",
    "img_data = {'train': Bird_Dataset_Process(train_file, root_dir, train_vectors, 4, data_transform),\n",
    "                  'test': Bird_Dataset_Process(test_file, root_dir, test_vectors, 4, data_transform)}\n",
    "loader_img = {x: torch.utils.data.DataLoader(img_data[x], batch_size=20,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(img_data[x]) for x in ['train', 'test']}\n",
    "print(img_data['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "                \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            start_time = time.time()        \n",
    "            if epoch % 5 == 0 and phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = param_group['lr']\n",
    "                    print(\"***********************\")\n",
    "                    print(\"learning rate = %f\" % lr)\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i_batch, sample_batched in enumerate(loader_img[phase]):\n",
    "                img0 = sample_batched['image0']\n",
    "                img1 = sample_batched['image1']\n",
    "                img2 = sample_batched['image2']\n",
    "                img3 = sample_batched['image3']\n",
    "                labels = sample_batched['label']\n",
    "                \n",
    "                img0 = img0.to(device)\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                img3 = img3.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output0 = model(img0)\n",
    "                    output1 = model(img1)\n",
    "                    output2 = model(img2)\n",
    "                    output3 = model(img3)\n",
    "                    outputs = output0 + output1 + output2 + output3\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * img1.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if i_batch % 50 == 0 and phase == 'train':\n",
    "                    print(\"Iteration %d, loss = %f\" % (i_batch, loss))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'test':\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            cost_time = (time.time() - start_time)/60.0\n",
    "            print('{} 1 epoch time: {:.2f}min'.format(\n",
    "                phase, cost_time))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 5.545182\n",
      "Iteration 50, loss = 5.281681\n",
      "Iteration 100, loss = 5.306508\n",
      "Iteration 150, loss = 5.294640\n",
      "Iteration 200, loss = 5.264226\n",
      "Iteration 250, loss = 5.142363\n",
      "train Loss: 5.2787 Acc: 0.0093\n",
      "train 1 epoch time: 3.88min\n",
      "test Loss: 5.0802 Acc: 0.0271\n",
      "test 1 epoch time: 1.99min\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "Iteration 0, loss = 5.185041\n",
      "Iteration 50, loss = 4.990376\n",
      "Iteration 100, loss = 4.987313\n",
      "Iteration 150, loss = 4.592115\n",
      "Iteration 200, loss = 4.405859\n",
      "Iteration 250, loss = 3.599209\n",
      "train Loss: 4.6330 Acc: 0.0671\n",
      "train 1 epoch time: 4.02min\n",
      "test Loss: 3.6179 Acc: 0.2133\n",
      "test 1 epoch time: 1.96min\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "Iteration 0, loss = 4.010584\n",
      "Iteration 50, loss = 4.016866\n",
      "Iteration 100, loss = 3.425609\n",
      "Iteration 150, loss = 3.883745\n",
      "Iteration 200, loss = 3.106911\n",
      "Iteration 250, loss = 3.049938\n",
      "train Loss: 3.4434 Acc: 0.2129\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 2.3990 Acc: 0.4270\n",
      "test 1 epoch time: 2.09min\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "Iteration 0, loss = 2.313922\n",
      "Iteration 50, loss = 3.080693\n",
      "Iteration 100, loss = 2.403597\n",
      "Iteration 150, loss = 2.815134\n",
      "Iteration 200, loss = 2.546061\n",
      "Iteration 250, loss = 2.148663\n",
      "train Loss: 2.5482 Acc: 0.3614\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.7492 Acc: 0.5682\n",
      "test 1 epoch time: 1.94min\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "Iteration 0, loss = 2.353986\n",
      "Iteration 50, loss = 1.704805\n",
      "Iteration 100, loss = 1.955632\n",
      "Iteration 150, loss = 2.233609\n",
      "Iteration 200, loss = 1.724472\n",
      "Iteration 250, loss = 2.321287\n",
      "train Loss: 2.0356 Acc: 0.4683\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.5895 Acc: 0.6163\n",
      "test 1 epoch time: 1.90min\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 1.180661\n",
      "Iteration 50, loss = 1.810323\n",
      "Iteration 100, loss = 1.612901\n",
      "Iteration 150, loss = 1.600409\n",
      "Iteration 200, loss = 1.855793\n",
      "Iteration 250, loss = 2.329503\n",
      "train Loss: 1.6908 Acc: 0.5581\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.3433 Acc: 0.6798\n",
      "test 1 epoch time: 1.89min\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "Iteration 0, loss = 1.110175\n",
      "Iteration 50, loss = 1.465244\n",
      "Iteration 100, loss = 1.103759\n",
      "Iteration 150, loss = 1.987652\n",
      "Iteration 200, loss = 1.324407\n",
      "Iteration 250, loss = 1.273306\n",
      "train Loss: 1.3995 Acc: 0.6168\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.2092 Acc: 0.6895\n",
      "test 1 epoch time: 1.91min\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "Iteration 0, loss = 1.502180\n",
      "Iteration 50, loss = 0.961329\n",
      "Iteration 100, loss = 0.514848\n",
      "Iteration 150, loss = 1.325782\n",
      "Iteration 200, loss = 1.925920\n",
      "Iteration 250, loss = 1.175454\n",
      "train Loss: 1.2225 Acc: 0.6595\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.1114 Acc: 0.7130\n",
      "test 1 epoch time: 1.93min\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "Iteration 0, loss = 1.257708\n",
      "Iteration 50, loss = 1.007574\n",
      "Iteration 100, loss = 0.913997\n",
      "Iteration 150, loss = 1.440544\n",
      "Iteration 200, loss = 0.952010\n",
      "Iteration 250, loss = 0.744279\n",
      "train Loss: 1.0774 Acc: 0.6969\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0710 Acc: 0.7157\n",
      "test 1 epoch time: 1.88min\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "Iteration 0, loss = 0.506777\n",
      "Iteration 50, loss = 0.759256\n",
      "Iteration 100, loss = 1.656339\n",
      "Iteration 150, loss = 0.880418\n",
      "Iteration 200, loss = 0.733243\n",
      "Iteration 250, loss = 1.191462\n",
      "train Loss: 0.9345 Acc: 0.7324\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.0368 Acc: 0.7352\n",
      "test 1 epoch time: 1.91min\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 1.057152\n",
      "Iteration 50, loss = 0.722689\n",
      "Iteration 100, loss = 1.180353\n",
      "Iteration 150, loss = 0.638091\n",
      "Iteration 200, loss = 0.775349\n",
      "Iteration 250, loss = 0.454237\n",
      "train Loss: 0.8573 Acc: 0.7583\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 1.0758 Acc: 0.7313\n",
      "test 1 epoch time: 2.22min\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "Iteration 0, loss = 0.647599\n",
      "Iteration 50, loss = 0.794440\n",
      "Iteration 100, loss = 0.354594\n",
      "Iteration 150, loss = 0.586495\n",
      "Iteration 200, loss = 1.363720\n",
      "Iteration 250, loss = 0.611893\n",
      "train Loss: 0.7905 Acc: 0.7736\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 0.9889 Acc: 0.7553\n",
      "test 1 epoch time: 2.09min\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "Iteration 0, loss = 0.638040\n",
      "Iteration 50, loss = 0.465520\n",
      "Iteration 100, loss = 0.529728\n",
      "Iteration 150, loss = 0.640819\n",
      "Iteration 200, loss = 0.194720\n",
      "Iteration 250, loss = 0.807531\n",
      "train Loss: 0.6925 Acc: 0.7983\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 0.9918 Acc: 0.7577\n",
      "test 1 epoch time: 1.92min\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "Iteration 0, loss = 0.587317\n",
      "Iteration 50, loss = 0.565286\n",
      "Iteration 100, loss = 0.699377\n",
      "Iteration 150, loss = 1.099114\n",
      "Iteration 200, loss = 0.761856\n",
      "Iteration 250, loss = 0.654843\n",
      "train Loss: 0.6207 Acc: 0.8215\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 0.9900 Acc: 0.7637\n",
      "test 1 epoch time: 1.90min\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "Iteration 0, loss = 0.278667\n",
      "Iteration 50, loss = 0.951106\n",
      "Iteration 100, loss = 0.870068\n",
      "Iteration 150, loss = 0.202912\n",
      "Iteration 200, loss = 0.148028\n",
      "Iteration 250, loss = 0.396308\n",
      "train Loss: 0.5652 Acc: 0.8270\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.0039 Acc: 0.7651\n",
      "test 1 epoch time: 1.91min\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.641315\n",
      "Iteration 50, loss = 0.703970\n",
      "Iteration 100, loss = 0.359382\n",
      "Iteration 150, loss = 0.190519\n",
      "Iteration 200, loss = 0.230866\n",
      "Iteration 250, loss = 0.982548\n",
      "train Loss: 0.5322 Acc: 0.8368\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0536 Acc: 0.7627\n",
      "test 1 epoch time: 1.96min\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "Iteration 0, loss = 0.505193\n",
      "Iteration 50, loss = 0.353108\n",
      "Iteration 100, loss = 0.568280\n",
      "Iteration 150, loss = 0.345083\n",
      "Iteration 200, loss = 0.517574\n",
      "Iteration 250, loss = 0.281176\n",
      "train Loss: 0.5075 Acc: 0.8452\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 0.9506 Acc: 0.7806\n",
      "test 1 epoch time: 1.95min\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "Iteration 0, loss = 0.201469\n",
      "Iteration 50, loss = 0.432871\n",
      "Iteration 100, loss = 0.434330\n",
      "Iteration 150, loss = 0.184640\n",
      "Iteration 200, loss = 0.251372\n",
      "Iteration 250, loss = 0.340554\n",
      "train Loss: 0.4575 Acc: 0.8662\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 0.9944 Acc: 0.7656\n",
      "test 1 epoch time: 1.94min\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "Iteration 0, loss = 0.185694\n",
      "Iteration 50, loss = 0.352211\n",
      "Iteration 100, loss = 0.320220\n",
      "Iteration 150, loss = 0.182627\n",
      "Iteration 200, loss = 0.247519\n",
      "Iteration 250, loss = 0.521976\n",
      "train Loss: 0.4160 Acc: 0.8704\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.0629 Acc: 0.7667\n",
      "test 1 epoch time: 1.91min\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "Iteration 0, loss = 0.649541\n",
      "Iteration 50, loss = 0.267905\n",
      "Iteration 100, loss = 0.477985\n",
      "Iteration 150, loss = 0.365203\n",
      "Iteration 200, loss = 0.411256\n",
      "Iteration 250, loss = 0.361459\n",
      "train Loss: 0.3735 Acc: 0.8884\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 1.0085 Acc: 0.7846\n",
      "test 1 epoch time: 1.94min\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.001000\n",
      "Iteration 0, loss = 0.379840\n",
      "Iteration 50, loss = 0.265936\n",
      "Iteration 100, loss = 0.018203\n",
      "Iteration 150, loss = 0.405955\n",
      "Iteration 200, loss = 0.381650\n",
      "Iteration 250, loss = 0.338748\n",
      "train Loss: 0.3396 Acc: 0.8957\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0154 Acc: 0.7806\n",
      "test 1 epoch time: 1.88min\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "Iteration 0, loss = 0.538813\n",
      "Iteration 50, loss = 0.774821\n",
      "Iteration 100, loss = 0.554182\n",
      "Iteration 150, loss = 0.370834\n",
      "Iteration 200, loss = 0.483236\n",
      "Iteration 250, loss = 0.071691\n",
      "train Loss: 0.3327 Acc: 0.8954\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 1.0369 Acc: 0.7670\n",
      "test 1 epoch time: 1.90min\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "Iteration 0, loss = 0.164635\n",
      "Iteration 50, loss = 0.560337\n",
      "Iteration 100, loss = 0.191728\n",
      "Iteration 150, loss = 0.128583\n",
      "Iteration 200, loss = 0.146943\n",
      "Iteration 250, loss = 0.700942\n",
      "train Loss: 0.3049 Acc: 0.9012\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.0726 Acc: 0.7824\n",
      "test 1 epoch time: 1.92min\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "Iteration 0, loss = 0.238427\n",
      "Iteration 50, loss = 0.016292\n",
      "Iteration 100, loss = 0.357699\n",
      "Iteration 150, loss = 0.241597\n",
      "Iteration 200, loss = 0.559029\n",
      "Iteration 250, loss = 0.090600\n",
      "train Loss: 0.1806 Acc: 0.9436\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 1.0457 Acc: 0.7962\n",
      "test 1 epoch time: 1.93min\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "Iteration 0, loss = 0.182211\n",
      "Iteration 50, loss = 0.282608\n",
      "Iteration 100, loss = 0.090893\n",
      "Iteration 150, loss = 0.128167\n",
      "Iteration 200, loss = 0.193052\n",
      "Iteration 250, loss = 0.023554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1339 Acc: 0.9576\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 0.9753 Acc: 0.8098\n",
      "test 1 epoch time: 1.92min\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000500\n",
      "Iteration 0, loss = 0.006133\n",
      "Iteration 50, loss = 0.178026\n",
      "Iteration 100, loss = 0.114911\n",
      "Iteration 150, loss = 0.030388\n",
      "Iteration 200, loss = 0.121490\n",
      "Iteration 250, loss = 0.087371\n",
      "train Loss: 0.1267 Acc: 0.9596\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.0358 Acc: 0.8015\n",
      "test 1 epoch time: 1.94min\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "Iteration 0, loss = 0.156917\n",
      "Iteration 50, loss = 0.100641\n",
      "Iteration 100, loss = 0.083963\n",
      "Iteration 150, loss = 0.007397\n",
      "Iteration 200, loss = 0.028196\n",
      "Iteration 250, loss = 0.069099\n",
      "train Loss: 0.1256 Acc: 0.9610\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0027 Acc: 0.8007\n",
      "test 1 epoch time: 1.95min\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "Iteration 0, loss = 0.180071\n",
      "Iteration 50, loss = 0.042499\n",
      "Iteration 100, loss = 0.406288\n",
      "Iteration 150, loss = 0.065361\n",
      "Iteration 200, loss = 0.109447\n",
      "Iteration 250, loss = 0.133734\n",
      "train Loss: 0.1113 Acc: 0.9641\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0604 Acc: 0.8095\n",
      "test 1 epoch time: 1.91min\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "Iteration 0, loss = 0.126528\n",
      "Iteration 50, loss = 0.135474\n",
      "Iteration 100, loss = 0.144850\n",
      "Iteration 150, loss = 0.103836\n",
      "Iteration 200, loss = 0.466728\n",
      "Iteration 250, loss = 0.084820\n",
      "train Loss: 0.1016 Acc: 0.9695\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.0747 Acc: 0.7991\n",
      "test 1 epoch time: 1.93min\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "Iteration 0, loss = 0.022285\n",
      "Iteration 50, loss = 0.124837\n",
      "Iteration 100, loss = 0.170991\n",
      "Iteration 150, loss = 0.014318\n",
      "Iteration 200, loss = 0.008696\n",
      "Iteration 250, loss = 0.016619\n",
      "train Loss: 0.0758 Acc: 0.9750\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.0543 Acc: 0.8157\n",
      "test 1 epoch time: 1.90min\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000250\n",
      "Iteration 0, loss = 0.036359\n",
      "Iteration 50, loss = 0.003460\n",
      "Iteration 100, loss = 0.035319\n",
      "Iteration 150, loss = 0.109874\n",
      "Iteration 200, loss = 0.010111\n",
      "Iteration 250, loss = 0.043016\n",
      "train Loss: 0.0701 Acc: 0.9778\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 1.0293 Acc: 0.8158\n",
      "test 1 epoch time: 1.90min\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "Iteration 0, loss = 0.063999\n",
      "Iteration 50, loss = 0.035665\n",
      "Iteration 100, loss = 0.144133\n",
      "Iteration 150, loss = 0.030595\n",
      "Iteration 200, loss = 0.079744\n",
      "Iteration 250, loss = 0.017046\n",
      "train Loss: 0.0535 Acc: 0.9848\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0662 Acc: 0.8169\n",
      "test 1 epoch time: 1.92min\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "Iteration 0, loss = 0.000226\n",
      "Iteration 50, loss = 0.001079\n",
      "Iteration 100, loss = 0.052448\n",
      "Iteration 150, loss = 0.014957\n",
      "Iteration 200, loss = 0.260352\n",
      "Iteration 250, loss = 0.029782\n",
      "train Loss: 0.0547 Acc: 0.9820\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.0838 Acc: 0.8171\n",
      "test 1 epoch time: 1.92min\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "Iteration 0, loss = 0.001364\n",
      "Iteration 50, loss = 0.114459\n",
      "Iteration 100, loss = 0.209513\n",
      "Iteration 150, loss = 0.095561\n",
      "Iteration 200, loss = 0.106594\n",
      "Iteration 250, loss = 0.199374\n",
      "train Loss: 0.0570 Acc: 0.9821\n",
      "train 1 epoch time: 4.01min\n",
      "test Loss: 1.1116 Acc: 0.8134\n",
      "test 1 epoch time: 1.93min\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "Iteration 0, loss = 0.007677\n",
      "Iteration 50, loss = 0.073475\n",
      "Iteration 100, loss = 0.032890\n",
      "Iteration 150, loss = 0.025239\n",
      "Iteration 200, loss = 0.083045\n",
      "Iteration 250, loss = 0.127671\n",
      "train Loss: 0.0512 Acc: 0.9833\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.0771 Acc: 0.8126\n",
      "test 1 epoch time: 1.92min\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.102198\n",
      "Iteration 50, loss = 0.051941\n",
      "Iteration 100, loss = 0.004080\n",
      "Iteration 150, loss = 0.008802\n",
      "Iteration 200, loss = 0.076068\n",
      "Iteration 250, loss = 0.010829\n",
      "train Loss: 0.0453 Acc: 0.9860\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.0880 Acc: 0.8203\n",
      "test 1 epoch time: 1.78min\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "Iteration 0, loss = 0.004179\n",
      "Iteration 50, loss = 0.006858\n",
      "Iteration 100, loss = 0.026523\n",
      "Iteration 150, loss = 0.001286\n",
      "Iteration 200, loss = 0.004963\n",
      "Iteration 250, loss = 0.003722\n",
      "train Loss: 0.0394 Acc: 0.9872\n",
      "train 1 epoch time: 3.99min\n",
      "test Loss: 1.1286 Acc: 0.8227\n",
      "test 1 epoch time: 1.85min\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "Iteration 0, loss = 0.422672\n",
      "Iteration 50, loss = 0.002186\n",
      "Iteration 100, loss = 0.031752\n",
      "Iteration 150, loss = 0.015698\n",
      "Iteration 200, loss = 0.101174\n",
      "Iteration 250, loss = 0.026794\n",
      "train Loss: 0.0453 Acc: 0.9872\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.0873 Acc: 0.8208\n",
      "test 1 epoch time: 1.87min\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "Iteration 0, loss = 0.007812\n",
      "Iteration 50, loss = 0.060490\n",
      "Iteration 100, loss = 0.000704\n",
      "Iteration 150, loss = 0.136568\n",
      "Iteration 200, loss = 0.004692\n",
      "Iteration 250, loss = 0.021013\n",
      "train Loss: 0.0402 Acc: 0.9875\n",
      "train 1 epoch time: 4.00min\n",
      "test Loss: 1.1222 Acc: 0.8221\n",
      "test 1 epoch time: 1.94min\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n",
      "Iteration 0, loss = 0.021792\n",
      "Iteration 50, loss = 0.001210\n",
      "Iteration 100, loss = 0.001040\n",
      "Iteration 150, loss = 0.005112\n",
      "Iteration 200, loss = 0.029761\n",
      "Iteration 250, loss = 0.005061\n",
      "train Loss: 0.0352 Acc: 0.9893\n",
      "train 1 epoch time: 3.95min\n",
      "test Loss: 1.1035 Acc: 0.8221\n",
      "test 1 epoch time: 1.46min\n",
      "\n",
      "Epoch 40/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000125\n",
      "Iteration 0, loss = 0.064509\n",
      "Iteration 50, loss = 0.002094\n",
      "Iteration 100, loss = 0.098440\n",
      "Iteration 150, loss = 0.025701\n",
      "Iteration 200, loss = 0.027248\n",
      "Iteration 250, loss = 0.048735\n",
      "train Loss: 0.0381 Acc: 0.9875\n",
      "train 1 epoch time: 3.91min\n",
      "test Loss: 1.1297 Acc: 0.8226\n",
      "test 1 epoch time: 1.41min\n",
      "\n",
      "Epoch 41/59\n",
      "----------\n",
      "Iteration 0, loss = 0.021065\n",
      "Iteration 50, loss = 0.006141\n",
      "Iteration 100, loss = 0.012913\n",
      "Iteration 150, loss = 0.073217\n",
      "Iteration 200, loss = 0.094508\n",
      "Iteration 250, loss = 0.007071\n",
      "train Loss: 0.0347 Acc: 0.9888\n",
      "train 1 epoch time: 3.95min\n",
      "test Loss: 1.1219 Acc: 0.8257\n",
      "test 1 epoch time: 1.37min\n",
      "\n",
      "Epoch 42/59\n",
      "----------\n",
      "Iteration 0, loss = 0.024144\n",
      "Iteration 50, loss = 0.054658\n",
      "Iteration 100, loss = 0.014396\n",
      "Iteration 150, loss = 0.038669\n",
      "Iteration 200, loss = 0.003510\n",
      "Iteration 250, loss = 0.148815\n",
      "train Loss: 0.0349 Acc: 0.9878\n",
      "train 1 epoch time: 3.94min\n",
      "test Loss: 1.1270 Acc: 0.8260\n",
      "test 1 epoch time: 1.38min\n",
      "\n",
      "Epoch 43/59\n",
      "----------\n",
      "Iteration 0, loss = 0.020358\n",
      "Iteration 50, loss = 0.013494\n",
      "Iteration 100, loss = 0.188838\n",
      "Iteration 150, loss = 0.009744\n",
      "Iteration 200, loss = 0.026386\n",
      "Iteration 250, loss = 0.000949\n",
      "train Loss: 0.0362 Acc: 0.9882\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1092 Acc: 0.8257\n",
      "test 1 epoch time: 1.33min\n",
      "\n",
      "Epoch 44/59\n",
      "----------\n",
      "Iteration 0, loss = 0.007482\n",
      "Iteration 50, loss = 0.003358\n",
      "Iteration 100, loss = 0.080666\n",
      "Iteration 150, loss = 0.035991\n",
      "Iteration 200, loss = 0.019363\n",
      "Iteration 250, loss = 0.004549\n",
      "train Loss: 0.0283 Acc: 0.9915\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.1440 Acc: 0.8259\n",
      "test 1 epoch time: 1.37min\n",
      "\n",
      "Epoch 45/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000063\n",
      "Iteration 0, loss = 0.003747\n",
      "Iteration 50, loss = 0.000008\n",
      "Iteration 100, loss = 0.014484\n",
      "Iteration 150, loss = 0.022257\n",
      "Iteration 200, loss = 0.009993\n",
      "Iteration 250, loss = 0.048897\n",
      "train Loss: 0.0282 Acc: 0.9913\n",
      "train 1 epoch time: 3.95min\n",
      "test Loss: 1.1511 Acc: 0.8240\n",
      "test 1 epoch time: 1.43min\n",
      "\n",
      "Epoch 46/59\n",
      "----------\n",
      "Iteration 0, loss = 0.000434\n",
      "Iteration 50, loss = 0.001251\n",
      "Iteration 100, loss = 0.019327\n",
      "Iteration 150, loss = 0.084309\n",
      "Iteration 200, loss = 0.020633\n",
      "Iteration 250, loss = 0.000025\n",
      "train Loss: 0.0326 Acc: 0.9885\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1221 Acc: 0.8250\n",
      "test 1 epoch time: 1.46min\n",
      "\n",
      "Epoch 47/59\n",
      "----------\n",
      "Iteration 0, loss = 0.001478\n",
      "Iteration 50, loss = 0.002134\n",
      "Iteration 100, loss = 0.000911\n",
      "Iteration 150, loss = 0.046959\n",
      "Iteration 200, loss = 0.007781\n",
      "Iteration 250, loss = 0.006860\n",
      "train Loss: 0.0327 Acc: 0.9907\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1266 Acc: 0.8252\n",
      "test 1 epoch time: 1.47min\n",
      "\n",
      "Epoch 48/59\n",
      "----------\n",
      "Iteration 0, loss = 0.021185\n",
      "Iteration 50, loss = 0.010202\n",
      "Iteration 100, loss = 0.327800\n",
      "Iteration 150, loss = 0.172160\n",
      "Iteration 200, loss = 0.012688\n",
      "Iteration 250, loss = 0.031595\n",
      "train Loss: 0.0318 Acc: 0.9897\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.1365 Acc: 0.8229\n",
      "test 1 epoch time: 1.37min\n",
      "\n",
      "Epoch 49/59\n",
      "----------\n",
      "Iteration 0, loss = 0.000994\n",
      "Iteration 50, loss = 0.004862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, loss = 0.000732\n",
      "Iteration 150, loss = 0.295150\n",
      "Iteration 200, loss = 0.041207\n",
      "Iteration 250, loss = 0.042267\n",
      "train Loss: 0.0305 Acc: 0.9918\n",
      "train 1 epoch time: 3.96min\n",
      "test Loss: 1.1326 Acc: 0.8241\n",
      "test 1 epoch time: 1.39min\n",
      "\n",
      "Epoch 50/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000031\n",
      "Iteration 0, loss = 0.001726\n",
      "Iteration 50, loss = 0.013185\n",
      "Iteration 100, loss = 0.001734\n",
      "Iteration 150, loss = 0.004486\n",
      "Iteration 200, loss = 0.023944\n",
      "Iteration 250, loss = 0.004339\n",
      "train Loss: 0.0274 Acc: 0.9918\n",
      "train 1 epoch time: 3.95min\n",
      "test Loss: 1.1379 Acc: 0.8250\n",
      "test 1 epoch time: 1.43min\n",
      "\n",
      "Epoch 51/59\n",
      "----------\n",
      "Iteration 0, loss = 0.015521\n",
      "Iteration 50, loss = 0.000888\n",
      "Iteration 100, loss = 0.014806\n",
      "Iteration 150, loss = 0.004018\n",
      "Iteration 200, loss = 0.035382\n",
      "Iteration 250, loss = 0.000687\n",
      "train Loss: 0.0312 Acc: 0.9898\n",
      "train 1 epoch time: 3.96min\n",
      "test Loss: 1.1365 Acc: 0.8252\n",
      "test 1 epoch time: 1.34min\n",
      "\n",
      "Epoch 52/59\n",
      "----------\n",
      "Iteration 0, loss = 0.004513\n",
      "Iteration 50, loss = 0.002846\n",
      "Iteration 100, loss = 0.002416\n",
      "Iteration 150, loss = 0.028722\n",
      "Iteration 200, loss = 0.002582\n",
      "Iteration 250, loss = 0.061795\n",
      "train Loss: 0.0308 Acc: 0.9892\n",
      "train 1 epoch time: 3.92min\n",
      "test Loss: 1.1381 Acc: 0.8262\n",
      "test 1 epoch time: 1.35min\n",
      "\n",
      "Epoch 53/59\n",
      "----------\n",
      "Iteration 0, loss = 0.036381\n",
      "Iteration 50, loss = 0.002679\n",
      "Iteration 100, loss = 0.010044\n",
      "Iteration 150, loss = 0.017315\n",
      "Iteration 200, loss = 0.016034\n",
      "Iteration 250, loss = 0.002801\n",
      "train Loss: 0.0273 Acc: 0.9923\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1423 Acc: 0.8284\n",
      "test 1 epoch time: 1.45min\n",
      "\n",
      "Epoch 54/59\n",
      "----------\n",
      "Iteration 0, loss = 0.080687\n",
      "Iteration 50, loss = 0.002134\n",
      "Iteration 100, loss = 0.034522\n",
      "Iteration 150, loss = 0.010384\n",
      "Iteration 200, loss = 0.000439\n",
      "Iteration 250, loss = 0.022212\n",
      "train Loss: 0.0268 Acc: 0.9920\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1454 Acc: 0.8271\n",
      "test 1 epoch time: 1.37min\n",
      "\n",
      "Epoch 55/59\n",
      "----------\n",
      "***********************\n",
      "learning rate = 0.000016\n",
      "Iteration 0, loss = 0.011856\n",
      "Iteration 50, loss = 0.015497\n",
      "Iteration 100, loss = 0.006833\n",
      "Iteration 150, loss = 0.039597\n",
      "Iteration 200, loss = 0.046461\n",
      "Iteration 250, loss = 0.074209\n",
      "train Loss: 0.0257 Acc: 0.9912\n",
      "train 1 epoch time: 3.94min\n",
      "test Loss: 1.1477 Acc: 0.8278\n",
      "test 1 epoch time: 1.39min\n",
      "\n",
      "Epoch 56/59\n",
      "----------\n",
      "Iteration 0, loss = 0.013663\n",
      "Iteration 50, loss = 0.000667\n",
      "Iteration 100, loss = 0.004125\n",
      "Iteration 150, loss = 0.019052\n",
      "Iteration 200, loss = 0.007745\n",
      "Iteration 250, loss = 0.012112\n",
      "train Loss: 0.0294 Acc: 0.9905\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1467 Acc: 0.8253\n",
      "test 1 epoch time: 1.42min\n",
      "\n",
      "Epoch 57/59\n",
      "----------\n",
      "Iteration 0, loss = 0.012283\n",
      "Iteration 50, loss = 0.000222\n",
      "Iteration 100, loss = 0.008628\n",
      "Iteration 150, loss = 0.001561\n",
      "Iteration 200, loss = 0.018463\n",
      "Iteration 250, loss = 0.058517\n",
      "train Loss: 0.0301 Acc: 0.9902\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.1471 Acc: 0.8259\n",
      "test 1 epoch time: 1.46min\n",
      "\n",
      "Epoch 58/59\n",
      "----------\n",
      "Iteration 0, loss = 0.001417\n",
      "Iteration 50, loss = 0.000183\n",
      "Iteration 100, loss = 0.001152\n",
      "Iteration 150, loss = 0.001425\n",
      "Iteration 200, loss = 0.017120\n",
      "Iteration 250, loss = 0.185422\n",
      "train Loss: 0.0256 Acc: 0.9915\n",
      "train 1 epoch time: 3.97min\n",
      "test Loss: 1.1496 Acc: 0.8260\n",
      "test 1 epoch time: 1.45min\n",
      "\n",
      "Epoch 59/59\n",
      "----------\n",
      "Iteration 0, loss = 0.001218\n",
      "Iteration 50, loss = 0.004105\n",
      "Iteration 100, loss = 0.004638\n",
      "Iteration 150, loss = 0.002814\n",
      "Iteration 200, loss = 0.011288\n",
      "Iteration 250, loss = 0.007231\n",
      "train Loss: 0.0287 Acc: 0.9913\n",
      "train 1 epoch time: 3.98min\n",
      "test Loss: 1.1468 Acc: 0.8260\n",
      "test 1 epoch time: 1.37min\n",
      "\n",
      "Training complete in 343m 44s\n",
      "Best val Acc: 0.828443\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "vgg_16 = models.vgg16(pretrained=True)\n",
    "vgg_16.classifier = nn.Sequential(*list(vgg_16.classifier.children())[:1])\n",
    "vgg_16.features[30] = nn.AvgPool2d(kernel_size=14, stride=1, padding=0)\n",
    "vgg_16.features.add_module('31', nn.Dropout(0.8)) \n",
    "vgg_16.classifier[0] = nn.Linear(in_features=512, out_features=200, bias=True)\n",
    "# vgg_16 = nn.DataParallel(vgg_16, device_ids=[2, 3])\n",
    "vgg_16 = vgg_16.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(vgg_16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "model = train_model(vgg_16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/home/lvlab/Pytorch/part_bird\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
