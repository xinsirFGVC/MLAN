{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization completed\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "print (\"initialization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird_Train_Dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_file, root_dir, transform=None):\n",
    "        f = open(train_file, 'r')\n",
    "        self.train_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.train_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample\n",
    "    \n",
    "        \n",
    "class Bird_Test_Dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, test_file, root_dir, transform=None):\n",
    "        f = open(test_file, 'r')\n",
    "        self.test_list = f.readlines()\n",
    "        f.close()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.test_list[idx]\n",
    "        img_dir_label = line.strip('\\n').split(' ')\n",
    "        img_dir = os.path.join(self.root_dir, img_dir_label[0])\n",
    "        image = io.imread(img_dir)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[:,:,np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "        label = int(img_dir_label[1])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Bird_Train_Dataset'>\n",
      "torch.Size([3, 448, 448])\n",
      "5994\n",
      "{'train': 5994, 'test': 5794}\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([448, 448]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.486,0.499,0.432], [0.229,0.225,0.263])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([448, 448]),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.486,0.499,0.432], [0.229,0.225,0.263])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "root_dir = '/home/lvlab/Pytorch/images'\n",
    "train_file = '/home/lvlab/Pytorch/train.txt'\n",
    "test_file = '/home/lvlab/Pytorch/test.txt'\n",
    "image_datasets = {'train': Bird_Train_Dataset(train_file, root_dir, data_transforms['train']),\n",
    "                  'test': Bird_Test_Dataset(test_file, root_dir, data_transforms['test'])}\n",
    "print(type(image_datasets['train']))\n",
    "print(image_datasets['train'][0]['image'].shape)\n",
    "print(len(image_datasets['train']))\n",
    "\n",
    "train_dataset = image_datasets['train']\n",
    "test_dataset = image_datasets['test']\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(dataloaders['train']):\n",
    "#     print(i_batch, sample_batched['image'].size(),\n",
    "#           sample_batched['label'].size())\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "print(dataset_sizes)\n",
    "# class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "                \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            start_time = time.time()        \n",
    "            if epoch % 5 == 0 and phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lr = param_group['lr']\n",
    "                    print(\"***********************\")\n",
    "                    print(\"learning rate = %f\" % lr)\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i_batch, sample_batched in enumerate(dataloaders[phase]):\n",
    "                inputs = sample_batched['image']\n",
    "                labels = sample_batched['label']\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if i_batch % 50 == 0 and phase == 'train':\n",
    "                    print(\"Iteration %d, loss = %f\" % (i_batch, loss))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'test':\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            cost_time = (time.time() - start_time)/60.0\n",
    "            print('{} 1 epoch time: {:.2f}min'.format(\n",
    "                phase, cost_time))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg_16 = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "\n",
    "vgg_16.classifier = nn.Sequential(*list(vgg_16.classifier.children())[:1])\n",
    "vgg_16.features[30] = nn.AvgPool2d(kernel_size=28, stride=1, padding=0)\n",
    "vgg_16.features.add_module('31', nn.Dropout(0.8)) \n",
    "vgg_16.classifier[0] = nn.Linear(in_features=512, out_features=200, bias=True)\n",
    "\n",
    "vgg_16 = vgg_16.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "optimizer_ft = optim.SGD(vgg_16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "model_best = train_model(vgg_16, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_best, '/home/xinsir/Pytorch/image_bird')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
